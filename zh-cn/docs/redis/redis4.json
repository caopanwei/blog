{
  "filename": "redis4.md",
  "__html": "<h1>Redis高可用集群RedisCluster详解</h1>\n<!-- TOC -->\n<ul>\n<li><a href=\"#redis%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4rediscluster%E8%AF%A6%E8%A7%A3\">Redis高可用集群RedisCluster详解</a>\n<ul>\n<li><a href=\"#1%E7%AE%80%E4%BB%8B%E5%8F%8A%E5%8E%9F%E7%90%86\">1.简介及原理</a>\n<ul>\n<li><a href=\"#11%E4%BB%80%E4%B9%88%E6%98%AFrediscluster\">1.1什么是RedisCluster?</a></li>\n<li><a href=\"#12%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%A6%82%E5%BF%B5\">1.2分布式数据库概念</a></li>\n<li><a href=\"#13%E5%88%86%E5%8C%BA%E8%A7%84%E5%88%99\">1.3分区规则</a></li>\n<li><a href=\"#14%E8%99%9A%E6%8B%9F%E6%A7%BD%E5%88%86%E5%8C%BA\">1.4虚拟槽分区</a></li>\n<li><a href=\"#15%E6%A7%BD%E9%94%AE%E6%95%B0%E6%8D%AE%E5%85%B3%E7%B3%BB\">1.5槽、键、数据关系</a></li>\n<li><a href=\"#16rediscluster%E7%9A%84%E7%BC%BA%E9%99%B7\">1.6RedisCluster的缺陷</a></li>\n</ul>\n</li>\n<li><a href=\"#2%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA\">2.集群环境搭建</a></li>\n<li><a href=\"#3%E9%9B%86%E7%BE%A4%E8%8A%82%E7%82%B9%E9%80%9A%E4%BF%A1gossip%E5%8D%8F%E8%AE%AE\">3.集群节点通信－Gossip协议</a></li>\n</ul>\n</li>\n</ul>\n<!-- /TOC -->\n<h2>1.简介及原理</h2>\n<h3>1.1什么是RedisCluster?</h3>\n<p>RedisCluster是Redis的分布式解决方案，在3.0版本后推出的方案，有效地解决了Redis分布式的需求，当遇到单机内存、并发等瓶颈时，可使用此方案来解决这些问题.</p>\n<h3>1.2分布式数据库概念</h3>\n<p>分布式数据库把整个数据按分区规则映射到多个节点，即把数据划分到多个节点上，每个节点负责整体数据的一个子集</p>\n<h3>1.3分区规则</h3>\n<p>常见的分区规则哈希分区和顺序分区，redis集群使用了哈希分区，顺序分区暂用不到，不做具体说明；<br>\nRedisCluster采用了哈希分区的“虚拟槽分区”方式（哈希分区分节点取余、一致性哈希分区和虚拟槽分区）。</p>\n<h3>1.4虚拟槽分区</h3>\n<p>槽：slot<br>\nRedisCluster采用此分区，所有的键根据哈希函数(CRC16[key]&amp;16383)映射到0－16383槽内，共16384个槽位，每个节点维护部分槽及槽所映射的键值数据<br>\n哈希函数: Hash()=CRC16[key]&amp;16383\n<img src=\"https://gitee.com/cpw/commonimage/raw/master/QQ20190421-001156@2x.png\" alt=\"\"></p>\n<h3>1.5槽、键、数据关系</h3>\n<p><img src=\"https://gitee.com/cpw/commonimage/raw/master/QQ20190421-091843@2x.png\" alt=\"\"></p>\n<h3>1.6RedisCluster的缺陷</h3>\n<ol>\n<li>键的批量操作支持有限，比如mset, mget，如果多个键映射在不同的槽，就不支持了   mset name james age 19</li>\n<li>键事务支持有限，当多个键分布在不同节点时无法使用事务，同一节点是支持事务</li>\n<li>键是数据分区的最小粒度，不能将一个很大的键值对映射到不同的节点</li>\n<li>不支持多数据库，只有0，select 0</li>\n<li>复制结构只支持单层结构，不支持树型结构。</li>\n</ol>\n<h2>2.集群环境搭建</h2>\n<p>6389为6379的从节点，6390为6380的从节点，6391为6381的从节点\n<img src=\"https://gitee.com/cpw/commonimage/raw/master/QQ20190421-092415@2x.png\" alt=\"\"></p>\n<ol>\n<li>\n<p>修改配置<br>\n分别修改6379、 6380、 7381、 6389、 6390、 6391配置文件</p>\n<pre><code> 以6379为例：\n  port 6379                      //节点端口\n    cluster-enabled yes              //开启集群模式\n    cluster-node-timeout 15000       //节点超时时间\n    cluster-config-file  /usr/local/bin/clustercon/data/nodes-6379.conf \n</code></pre>\n</li>\n</ol>\n<p>集群内部配置文件,其它节点的配置和这个一致，改端口即可</p>\n<ol start=\"2\">\n<li>\n<p>服务启动<br>\n分别启动redis6379、6380、6381、 6389、 6390、 6391节点</p>\n<pre><code> ./redis-server clusterconf/redis6379.conf &amp;\n ./redis-server clusterconf/redis6380.conf &amp;\n ./redis-server clusterconf/redis6381.conf &amp;\n ./redis-server clusterconf/redis6389.conf &amp;\n ./redis-server clusterconf/redis6390.conf &amp;\n ./redis-server clusterconf/redis6391.conf &amp;\n</code></pre>\n</li>\n<li>\n<p>集群启动</p>\n<p>启动命令:</p>\n<pre><code> src/redis-cli --cluster create 10.211.55.5:6379 10.211.55.5:6389 10.211.55.5:6380  10.211.55.5:6390  10.211.55.5:6381 10.211.55.5:6391 --cluster-replicas 1\n //cluster-replicas 1 表示1主1从 ,配置多从可以修改该配置\n</code></pre>\n<p>执行成功后截图:</p>\n<pre><code> [root@master redis-5.0.4]# src/redis-cli --cluster create 10.211.55.5:6379 10.211.55.5:6389 10.211.55.5:6380  10.211.55.5:6390  10.211.55.5:6381 10.211.55.5:6391 --cluster-replicas 1\n &gt;&gt;&gt; Performing hash slots allocation on 6 nodes...\n Master[0] -&gt; Slots 0 - 5460\n Master[1] -&gt; Slots 5461 - 10922\n Master[2] -&gt; Slots 10923 - 16383\n Adding replica 10.211.55.5:6381 to 10.211.55.5:6379\n Adding replica 10.211.55.5:6391 to 10.211.55.5:6389\n Adding replica 10.211.55.5:6390 to 10.211.55.5:6380\n &gt;&gt;&gt; Trying to optimize slaves allocation for anti-affinity\n [WARNING] Some slaves are in the same host as their master\n M: 3b0dadbb21f6fa82d02bc38633b13dedf1069a24 10.211.55.5:6379\n    slots:[0-5460] (5461 slots) master\n M: f55911e14d10853af291205a73473e02818b9f89 10.211.55.5:6389\n    slots:[5461-10922] (5462 slots) master\n M: a2f83baaa1045c3efdce704b0a4ade1bd7412ad5 10.211.55.5:6380\n    slots:[10923-16383] (5461 slots) master\n S: c00501b56bd4df4ea5edde0e48bfbe0006f9dd21 10.211.55.5:6390\n    replicates f55911e14d10853af291205a73473e02818b9f89\n S: 08738cf9c06d079c47d525d080e7befbc12cc69b 10.211.55.5:6381\n    replicates a2f83baaa1045c3efdce704b0a4ade1bd7412ad5\n S: 4306adfa4f38f60a4c367544adc9717b5aa7215c 10.211.55.5:6391\n    replicates 3b0dadbb21f6fa82d02bc38633b13dedf1069a24\n Can I set the above configuration? (type 'yes' to accept): yes\n &gt;&gt;&gt; Nodes configuration updated\n &gt;&gt;&gt; Assign a different config epoch to each node\n &gt;&gt;&gt; Sending CLUSTER MEET messages to join the cluster\n Waiting for the cluster to join\n ...\n &gt;&gt;&gt; Performing Cluster Check (using node 10.211.55.5:6379)\n M: 3b0dadbb21f6fa82d02bc38633b13dedf1069a24 10.211.55.5:6379\n    slots:[0-5460] (5461 slots) master\n    1 additional replica(s)\n M: a2f83baaa1045c3efdce704b0a4ade1bd7412ad5 10.211.55.5:6380\n    slots:[10923-16383] (5461 slots) master\n    1 additional replica(s)\n M: f55911e14d10853af291205a73473e02818b9f89 10.211.55.5:6389\n    slots:[5461-10922] (5462 slots) master\n    1 additional replica(s)\n S: 4306adfa4f38f60a4c367544adc9717b5aa7215c 10.211.55.5:6391\n    slots: (0 slots) slave\n    replicates 3b0dadbb21f6fa82d02bc38633b13dedf1069a24\n S: c00501b56bd4df4ea5edde0e48bfbe0006f9dd21 10.211.55.5:6390\n    slots: (0 slots) slave\n    replicates f55911e14d10853af291205a73473e02818b9f89\n S: 08738cf9c06d079c47d525d080e7befbc12cc69b 10.211.55.5:6381\n    slots: (0 slots) slave\n    replicates a2f83baaa1045c3efdce704b0a4ade1bd7412ad5\n [OK] All nodes agree about slots configuration.\n &gt;&gt;&gt; Check for open slots...\n &gt;&gt;&gt; Check slots coverage...\n [OK] All 16384 slots covered.\n [root@master redis-5.0.4]#\n</code></pre>\n</li>\n<li>\n<p>集群检测<br>\n1.检测集群状态slots详细分配</p>\n<pre><code> 执行命令:\n src/redis-cli --cluster check 10.211.55.5:6379\n \n 打印结果如下:\n [root@master redis-5.0.4]# src/redis-cli --cluster info 10.211.55.5:6379\n 10.211.55.5:6379 (3b0dadbb...) -&gt; 0 keys | 5461 slots | 1 slaves.\n 10.211.55.5:6380 (a2f83baa...) -&gt; 0 keys | 5461 slots | 1 slaves.\n 10.211.55.5:6389 (f55911e1...) -&gt; 0 keys | 5462 slots | 1 slaves.\n</code></pre>\n<p>2.检查集群状态</p>\n<pre><code> 执行命令:\n src/redis-cli --cluster info 10.211.55.5:6379\n \n 打印结果如下:\n [root@master redis-5.0.4]# src/redis-cli --cluster check 10.211.55.5:6379\n 10.211.55.5:6379 (3b0dadbb...) -&gt; 0 keys | 5461 slots | 1 slaves.\n 10.211.55.5:6380 (a2f83baa...) -&gt; 0 keys | 5461 slots | 1 slaves.\n 10.211.55.5:6389 (f55911e1...) -&gt; 0 keys | 5462 slots | 1 slaves.\n [OK] 0 keys in 3 masters.\n 0.00 keys per slot on average.\n &gt;&gt;&gt; Performing Cluster Check (using node 10.211.55.5:6379)\n M: 3b0dadbb21f6fa82d02bc38633b13dedf1069a24 10.211.55.5:6379\n    slots:[0-5460] (5461 slots) master\n    1 additional replica(s)\n M: a2f83baaa1045c3efdce704b0a4ade1bd7412ad5 10.211.55.5:6380\n    slots:[10923-16383] (5461 slots) master\n    1 additional replica(s)\n M: f55911e14d10853af291205a73473e02818b9f89 10.211.55.5:6389\n    slots:[5461-10922] (5462 slots) master\n    1 additional replica(s)\n S: 4306adfa4f38f60a4c367544adc9717b5aa7215c 10.211.55.5:6391\n    slots: (0 slots) slave\n    replicates 3b0dadbb21f6fa82d02bc38633b13dedf1069a24\n S: c00501b56bd4df4ea5edde0e48bfbe0006f9dd21 10.211.55.5:6390\n    slots: (0 slots) slave\n    replicates f55911e14d10853af291205a73473e02818b9f89\n S: 08738cf9c06d079c47d525d080e7befbc12cc69b 10.211.55.5:6381\n    slots: (0 slots) slave\n    replicates a2f83baaa1045c3efdce704b0a4ade1bd7412ad5\n [OK] All nodes agree about slots configuration.\n &gt;&gt;&gt; Check for open slots...\n &gt;&gt;&gt; Check slots coverage...\n [OK] All 16384 slots covered.\n [root@master redis-5.0.4]#\n</code></pre>\n</li>\n<li>\n<p>Redis集群命令</p>\n<pre><code> [root@master redis-5.0.4]# src/redis-cli --cluster help\n Cluster Manager Commands:\n   create         host1:port1 ... hostN:portN\n                  --cluster-replicas &lt;arg&gt;\n   check          host:port\n                  --cluster-search-multiple-owners\n   info           host:port\n   fix            host:port\n                  --cluster-search-multiple-owners\n   reshard        host:port\n                  --cluster-from &lt;arg&gt;\n                  --cluster-to &lt;arg&gt;\n                  --cluster-slots &lt;arg&gt;\n                  --cluster-yes\n                  --cluster-timeout &lt;arg&gt;\n                  --cluster-pipeline &lt;arg&gt;\n                  --cluster-replace\n   rebalance      host:port\n                  --cluster-weight &lt;node1=w1...nodeN=wN&gt;\n                  --cluster-use-empty-masters\n                  --cluster-timeout &lt;arg&gt;\n                  --cluster-simulate\n                  --cluster-pipeline &lt;arg&gt;\n                  --cluster-threshold &lt;arg&gt;\n                  --cluster-replace\n   add-node       new_host:new_port existing_host:existing_port\n                  --cluster-slave\n                  --cluster-master-id &lt;arg&gt;\n   del-node       host:port node_id\n   call           host:port command arg arg .. arg\n   set-timeout    host:port milliseconds\n   import         host:port\n                  --cluster-from &lt;arg&gt;\n                  --cluster-copy\n                  --cluster-replace\n   help\n \n For check, fix, reshard, del-node, set-timeout you can specify the host and port of any working node in the cluster.\n \n [root@master redis-5.0.4]#\n \n // add-node 新增节点\n @新增主节点\n &gt;redis-cli --cluster add-node 127.0.0.1:7006 127.0.0.1:7000\n 将新节点的地址指定为第一个参数，并将集群中随机存在节点的地址指定为第二个参数\n &gt;使用reshard命令对该主节点分配哈希槽\n @新增从节点\n redis-cli --cluster add-node 127.0.0.1:7006 127.0.0.1:7000 --cluster-slave //随机添加到从节点较少的主节点上\n redis-cli --cluster add-node 127.0.0.1:7006 127.0.0.1:7000 --cluster-slave --cluster-master-id 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e  //指定添加为该主节点id的从节点\n @主节点转化为从节点\n 登录该主节点,执行以下命令即可转为该节点id的从节点\n redis 127.0.0.1:7006&gt; cluster replicate 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e\n \n // del-node 删除从节点\n redis-cli --cluster del-node 127.0.0.1:7000 `&lt;node-id&gt;`\n 第一个参数只是集群中的随机节点，第二个参数是要删除的节点的ID。\n</code></pre>\n</li>\n</ol>\n<h2>3.集群节点通信－Gossip协议</h2>\n<ol>\n<li>\n<p>什么是gossip协议<br>\n节点之间采用Gossip协议进行通信，Gossip协议就是指节点彼此之间不断通信交换信息\n<img src=\"https://gitee.com/cpw/commonimage/raw/master/QQ20190421-231609@2x.png\" alt=\"\">\n当主从角色变化或新增节点，彼此通过ping/pong进行通信知道全部节点的最新状态并达到集群同步</p>\n</li>\n<li>\n<p>gossip协议的作用<br>\nGossip协议的主要职责就是信息交换，信息交换的载体就是节点之间彼此发送的Gossip消息，常用的Gossip消息有ping消息、pong消息、meet消息、fail消息<br>\nmeet消息：用于通知新节点加入，消息发送者通知接收者加入到当前集群，meet消息通信完后，接收节点会加入到集群中，并进行周期性ping pong交换<br>\nping消息：集群内交换最频繁的消息，集群内每个节点每秒向其它节点发ping消息，用于检测节点是在在线和状态信息，ping消息发送封装自身节点和其他节点的状态数据；<br>\npong消息，当接收到ping meet消息时，作为响应消息返回给发送方，用来确认正常通信，pong消息也封闭了自身状态数据；<br>\nfail消息：当节点判定集群内的另一节点下线时，会向集群内广播一个fail消息<br>\n<img src=\"https://gitee.com/cpw/commonimage/raw/master/QQ20190421-231621@2x.png\" alt=\"\"></p>\n</li>\n<li>\n<p>gossip协议的消息解析流程\n以上的所有消息格式为：消息头、消息体，消息头包含发送节点自身状态数据（比如节点ID、槽映射、节点角色、是否下线等），接收节点根据消息头可以获取到发送节点的相关数据。\n<img src=\"https://gitee.com/cpw/commonimage/raw/master/QQ20190421-231637@2x.png\" alt=\"\"></p>\n</li>\n<li>\n<p>选择节点后并发关ping消息\nGossip协议信息的交换机制具有天然的分布式特性，但ping pong发送的频率很高\n<img src=\"https://gitee.com/cpw/commonimage/raw/master/QQ20190421-231649@2x.png\" alt=\"\"></p>\n</li>\n</ol>\n",
  "link": "/zh-cn/docs/redis/redis4.html",
  "meta": {}
}